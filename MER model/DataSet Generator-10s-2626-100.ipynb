{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wNiwWX4owKJ3",
    "outputId": "bf7eadce-b5a3-47cb-d4c1-4f7bd70e9fb0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /opt/conda/lib/python3.11/site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.11/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /opt/conda/lib/python3.11/site-packages (from librosa) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from librosa) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.11/site-packages (from librosa) (1.5.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.11/site-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.11/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.11/site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.11/site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /opt/conda/lib/python3.11/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.11/site-packages (from librosa) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.11/site-packages (from librosa) (4.9.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.11/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.11/site-packages (from librosa) (1.0.8)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from lazy-loader>=0.1->librosa) (23.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.11/site-packages (from pooch>=1.1->librosa) (4.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.11/site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2023.11.17)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wIpc_W-jv9cv"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z6RIdDc0FfU8",
    "outputId": "0b624540-d5f4-4d21-e448-6e7f24fcba00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda.\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gCKOaHfJGx2L"
   },
   "outputs": [],
   "source": [
    "arousal = pd.read_csv('annotation/arousal.csv').to_numpy()[:,1:58]\n",
    "valence = pd.read_csv('annotation/valence.csv').to_numpy()[:,1:58]\n",
    "song_ids_list = pd.read_csv('annotation/valence.csv').to_numpy()[:,0].tolist()\n",
    "song_ids_list = list(map(int, song_ids_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1802, 57)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arousal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sample_by_cluster(data, test_ratio):\n",
    "    unique_clusters = np.unique(data[:, -1])\n",
    "    test_indices = np.array([], dtype=int)\n",
    "    train_indices = np.array([], dtype=int)\n",
    "\n",
    "    for cluster in unique_clusters:\n",
    "        cluster_indices = np.where(data[:, -1] == cluster)[0]\n",
    "        test_size = int(len(cluster_indices) * test_ratio)\n",
    "        test_cluster_indices = np.random.choice(cluster_indices, size=test_size, replace=False)\n",
    "        train_cluster_indices = np.array(list(set(cluster_indices) - set(test_cluster_indices)), dtype=int)\n",
    "        test_indices = np.concatenate([test_indices, test_cluster_indices])\n",
    "        train_indices = np.concatenate([train_indices, train_cluster_indices])\n",
    "\n",
    "    return data[train_indices], data[test_indices]\n",
    "\n",
    "def sampling_K_Mean(Y,test_ratio):\n",
    "    kmeans = KMeans(n_clusters=10, random_state=42).fit(Y[:,1:])\n",
    "    clusters = kmeans.labels_\n",
    "    data_with_clusters = np.column_stack((Y, clusters))\n",
    "    train_data, test_data = stratified_sample_by_cluster(data_with_clusters, test_ratio=test_ratio)\n",
    "    X_train = train_data[:, :-1]\n",
    "    X_test = test_data[:, :-1]\n",
    "    \n",
    "    return X_train[:,0].astype(int),X_test[:,0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "O7r_KUTdGbid"
   },
   "outputs": [],
   "source": [
    "def Audio_seq_generator(song_ids_list,song_ids,arousal,valence,n_mels,n_MFCCs):\n",
    "    X=[]\n",
    "    #X_F=[]\n",
    "    Y=[]\n",
    "    for song_id in song_ids:\n",
    "        #feature = pd.read_csv(f'features/{song_id}.csv',sep=';').apply(pd.to_numeric, errors='coerce').to_numpy()[31:88,:]\n",
    "        #if feature.shape != (57,261):\n",
    "            #print(song_id,feature.shape)\n",
    "        #else:\n",
    "            audio,sr = librosa.load(f\"Audio/{song_id}.mp3\",sr=44100)\n",
    "            audio=audio[:sr*45]\n",
    "            \n",
    "            S = librosa.feature.melspectrogram(y=audio,sr=sr,n_mels=n_mels,hop_length=441)\n",
    "            S = S[:,:4500-45]\n",
    "            S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "            SS = S_dB.reshape(n_mels,4500-45)\n",
    "            \n",
    "            zcr = librosa.feature.zero_crossing_rate(audio,hop_length=441)\n",
    "            zcr = zcr[:,:4500-45]\n",
    "    \n",
    "            mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_MFCCs,hop_length=441)\n",
    "            mfccs = mfccs[:,:4500-45]\n",
    "            #print(SS.shape,zcr.shape)\n",
    "            F = np.vstack((SS,zcr,mfccs))\n",
    "            X.append(F)\n",
    "            \n",
    "            Y_index = song_ids_list.index(song_id)\n",
    "            Y_seq = torch.tensor(np.stack((arousal[Y_index,:],valence[Y_index,:]),axis=1))\n",
    "            Y_seq = [Y_seq[i*10:i*10+20].mean(dim=0)  for i in range(4)]\n",
    "            Y_seq = torch.stack(Y_seq)\n",
    "            Y.append(Y_seq) \n",
    "            \n",
    "            \n",
    "            #feature = torch.tensor(feature)\n",
    "            #feature = [feature[i*10:i*10+10].mean(dim=0)  for i in range(5)]\n",
    "            #feature = torch.stack(feature)\n",
    "            #X_F.append(feature)\n",
    "    X=torch.tensor(np.stack(X,axis=0))\n",
    "    #X_F=torch.tensor(np.stack(X_F,axis=0))\n",
    "    Y=torch.tensor(np.stack(Y,axis=0))\n",
    "    X = [X[:,:,i*500+1500:i*500+2500] for i in range(4)]\n",
    "    X = torch.tensor(np.stack(X,axis=1))\n",
    "    X = [X[:,:,:,i*100:i*100+100] for i in range(10)]\n",
    "    X = torch.tensor(np.stack(X,axis=2))\n",
    "    return X,Y#X_F,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CYf3LL8pbRU1",
    "outputId": "384b1f1d-5653-49dd-ac37-0d74496ed999"
   },
   "outputs": [],
   "source": [
    "X, Y=Audio_seq_generator(song_ids_list,song_ids_list[0:900],arousal,valence,26,26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, Y2=Audio_seq_generator(song_ids_list,song_ids_list[900:],arousal,valence,26,26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X=torch.cat((X,X2),dim=0)\n",
    "Y=torch.cat((Y,Y2),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.reshape(X.shape[0]*X.shape[1],X.shape[2],X.shape[3],X.shape[4])\n",
    "Y=Y.reshape(Y.shape[0]*Y.shape[1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7208, 10, 53, 100]) torch.Size([7208, 2])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set X shape: torch.Size([5045, 10, 53, 100])\n",
      "Training set Y shape: torch.Size([5045, 2])\n",
      "Test set X shape: torch.Size([2163, 10, 53, 100])\n",
      "Test set Y shape: torch.Size([2163, 2])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "labels = torch.zeros(Y.shape[0], dtype=torch.int64)  # Create a tensor for labels\n",
    "labels[(Y[:,0] > 0) & (Y[:,1] > 0)] = 0\n",
    "labels[(Y[:,0] > 0) & (Y[:,1] < 0)] = 1\n",
    "labels[(Y[:,0] < 0) & (Y[:,1] > 0)] = 2\n",
    "labels[(Y[:,0] < 0) & (Y[:,1] < 0)] = 3\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "train_idx, test_idx = next(sss.split(X, labels))\n",
    "\n",
    "# 使用索引从合并的张量中获取训练集和测试集\n",
    "train_X = X[train_idx]\n",
    "train_Y = Y[train_idx]\n",
    "test_X = X[test_idx]\n",
    "test_Y = Y[test_idx]\n",
    "\n",
    "# 检查结果\n",
    "print(\"Training set X shape:\", train_X.shape)\n",
    "print(\"Training set Y shape:\", train_Y.shape)\n",
    "print(\"Test set X shape:\", test_X.shape)\n",
    "print(\"Test set Y shape:\", test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(train_X,'Data/X_train_10s_all_2626_100.pt')\n",
    "torch.save(train_Y,'Data/Y_train_10s_all_2626_100.pt')\n",
    "torch.save(test_X,'Data/X_val_10s_all_2626_100.pt')\n",
    "torch.save(test_Y,'Data/Y_val_10s_all_2626_100.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
